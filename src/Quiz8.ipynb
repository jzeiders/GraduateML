{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 0.27\n",
    "# 2 5\n",
    "# 3 Line is x2 > 6 == 0\n",
    "# 4) MLE may not exist, non-negative, local is global\n",
    "\n",
    "# Later parts\n",
    "#1) Does bfgs work?\n",
    "\n",
    "\n",
    "# [a1] =\n",
    "# [b1] = 48\n",
    "# [c1] = 0.741\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a1] = 24\n",
      "[b1] = 48\n",
      "[c1] = 0.741\n",
      "[d2] = 15\n",
      "[a2] = 13\n",
      "[b2] = 54\n",
      "[c2] = 0.743\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m selected\n\u001b[0;32m--> 122\u001b[0m selected_bic \u001b[38;5;241m=\u001b[39m \u001b[43mforward_selection_bic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m d3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected_bic)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Fit logistic regression with selected features\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 109\u001b[0m, in \u001b[0;36mforward_selection_bic\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    107\u001b[0m scores_with_candidates \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m candidate \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[0;32m--> 109\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLogit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     bic \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbic\n\u001b[1;32m    111\u001b[0m     scores_with_candidates\u001b[38;5;241m.\u001b[39mappend((bic, candidate))\n",
      "File \u001b[0;32m~/Documents/Code/Learnings/GraduateML/.direnv/python-3.11/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:2601\u001b[0m, in \u001b[0;36mLogit.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[1;32m   2600\u001b[0m         full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2601\u001b[0m     bnryfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2609\u001b[0m     discretefit \u001b[38;5;241m=\u001b[39m LogitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[1;32m   2610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[0;32m~/Documents/Code/Learnings/GraduateML/.direnv/python-3.11/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:243\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "File \u001b[0;32m~/Documents/Code/Learnings/GraduateML/.direnv/python-3.11/lib/python3.11/site-packages/statsmodels/base/model.py:582\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m cov_params_func(\u001b[38;5;28mself\u001b[39m, xopt, retvals)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m full_output:\n\u001b[0;32m--> 582\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mretvals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHessian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hessian:\n\u001b[1;32m    584\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhessian(xopt)\n",
      "File \u001b[0;32m~/Documents/Code/Learnings/GraduateML/.direnv/python-3.11/lib/python3.11/site-packages/numpy/linalg/_linalg.py:608\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    605\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call\u001b[38;5;241m=\u001b[39m_raise_linalgerror_singular, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    607\u001b[0m               over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 608\u001b[0m     ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/Documents/Code/Learnings/GraduateML/.direnv/python-3.11/lib/python3.11/site-packages/numpy/linalg/_linalg.py:104\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools import add_constant\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load the data\n",
    "url = \"https://liangfgithub.github.io/Data/Caravan.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Encode the response variable\n",
    "data['Purchase'] = data['Purchase'].map({'No':0, 'Yes':1})\n",
    "\n",
    "# Split into test and training\n",
    "test_data = data.iloc[:1000]\n",
    "train_data = data.iloc[1000:]\n",
    "\n",
    "X_train = train_data.drop('Purchase', axis=1)\n",
    "y_train = train_data['Purchase']\n",
    "X_test = test_data.drop('Purchase', axis=1)\n",
    "y_test = test_data['Purchase']\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Function to calculate misclassifications and AUC\n",
    "def evaluate_model(model, X, y, cutoff=0.25):\n",
    "    probs = model.predict_proba(X)[:,1]\n",
    "    preds = (probs >= cutoff).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, preds).ravel()\n",
    "    auc = roc_auc_score(y, probs)\n",
    "    return fp, fn, auc\n",
    "\n",
    "### **Question [a1], [b1], [c1]: Logistic Regression with All Predictors**\n",
    "\n",
    "# Fit logistic regression with all predictors\n",
    "log_reg = LogisticRegression(penalty=None,max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "a1, b1, c1 = evaluate_model(log_reg, X_test_scaled, y_test)\n",
    "\n",
    "print(f\"[a1] = {a1}\")\n",
    "print(f\"[b1] = {b1}\")\n",
    "print(f\"[c1] = {c1:.3f}\")\n",
    "\n",
    "### **Forward Variable Selection Using AIC**\n",
    "\n",
    "# Add constant for statsmodels\n",
    "X_train_sm = add_constant(X_train)\n",
    "X_test_sm = add_constant(X_test)\n",
    "\n",
    "# Fit model using statsmodels to perform forward selection based on AIC\n",
    "def forward_selection_aic(X, y):\n",
    "    cols = list(X.columns)\n",
    "    selected = []\n",
    "    current_score, best_new_score = np.inf, np.inf\n",
    "    while cols:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in cols:\n",
    "            model = sm.Logit(y, X[selected + [candidate]]).fit(disp=0, method='bfgs')\n",
    "            aic = model.aic\n",
    "            scores_with_candidates.append((aic, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates[0]\n",
    "        if best_new_score < current_score:\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "            cols.remove(best_candidate)\n",
    "        else:\n",
    "            break\n",
    "    return selected\n",
    "\n",
    "selected_aic = forward_selection_aic(X_train_sm.drop('const', axis=1), y_train)\n",
    "d2 = len(selected_aic)\n",
    "\n",
    "# Fit logistic regression with selected features\n",
    "log_reg_aic = LogisticRegression(max_iter=1000, penalty=None)\n",
    "log_reg_aic.fit(X_train_scaled[:, [X_train.columns.get_loc(col) for col in selected_aic]], y_train)\n",
    "\n",
    "# Prepare test data\n",
    "X_test_aic = X_test_scaled[:, [X_train.columns.get_loc(col) for col in selected_aic]]\n",
    "\n",
    "# Evaluate\n",
    "a2, b2, c2 = evaluate_model(log_reg_aic, X_test_aic, y_test)\n",
    "\n",
    "print(f\"[d2] = {d2}\")\n",
    "print(f\"[a2] = {a2}\")\n",
    "print(f\"[b2] = {b2}\")\n",
    "print(f\"[c2] = {c2:.3f}\")\n",
    "\n",
    "### **Forward Variable Selection Using BIC**\n",
    "\n",
    "# Fit model using statsmodels to perform forward selection based on BIC\n",
    "def forward_selection_bic(X, y):\n",
    "    cols = list(X.columns)\n",
    "    selected = []\n",
    "    current_bic, best_new_bic = np.inf, np.inf\n",
    "    while cols:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in cols:\n",
    "            model = sm.Logit(y, X[selected + [candidate]]).fit(disp=0)\n",
    "            bic = model.bic\n",
    "            scores_with_candidates.append((bic, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_bic, best_candidate = scores_with_candidates[0]\n",
    "        if best_new_bic < current_bic:\n",
    "            selected.append(best_candidate)\n",
    "            current_bic = best_new_bic\n",
    "            cols.remove(best_candidate)\n",
    "        else:\n",
    "            break\n",
    "    return selected\n",
    "\n",
    "selected_bic = forward_selection_bic(X_train_sm.drop('const', axis=1), y_train)\n",
    "d3 = len(selected_bic)\n",
    "\n",
    "# Fit logistic regression with selected features\n",
    "log_reg_bic = LogisticRegression(max_iter=1000)\n",
    "log_reg_bic.fit(X_train_scaled[:, [X_train.columns.get_loc(col) for col in selected_bic]], y_train)\n",
    "\n",
    "# Prepare test data\n",
    "X_test_bic = X_test_scaled[:, [X_train.columns.get_loc(col) for col in selected_bic]]\n",
    "\n",
    "# Evaluate\n",
    "a3, b3, c3 = evaluate_model(log_reg_bic, X_test_bic, y_test)\n",
    "\n",
    "print(f\"[d3] = {d3}\")\n",
    "print(f\"[a3] = {a3}\")\n",
    "print(f\"[b3] = {b3}\")\n",
    "print(f\"[c3] = {c3:.3f}\")\n",
    "\n",
    "### **L1 Penalty (Lasso) Logistic Regression**\n",
    "\n",
    "# Fit L1-penalized logistic regression\n",
    "log_reg_l1 = LogisticRegression(penalty='l1', C=1/0.004, solver='liblinear', max_iter=1000)\n",
    "log_reg_l1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Number of non-intercept predictors (non-zero coefficients)\n",
    "d4 = np.sum(log_reg_l1.coef_ != 0)\n",
    "\n",
    "# Evaluate on test data\n",
    "a4, b4, c4 = evaluate_model(log_reg_l1, X_test_scaled, y_test)\n",
    "\n",
    "print(f\"[d4] = {d4}\")\n",
    "print(f\"[a4] = {a4}\")\n",
    "print(f\"[b4] = {b4}\")\n",
    "print(f\"[c4] = {c4:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
