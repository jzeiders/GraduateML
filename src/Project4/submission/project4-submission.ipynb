{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# John Zeiders Project 4 Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from itertools import combinations\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('recommender.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ratings matrix with shape: (6040, 3706)\n",
      "Loaded 3883 movies\n"
     ]
    }
   ],
   "source": [
    "ratings_matrix = pd.read_csv('/Users/jzeiders/Documents/Code/Learnings/GraduateML/src/Project4/submission/rating_matrix.csv', index_col=0)\n",
    "\n",
    "# Load movie data\n",
    "movie_data = {}\n",
    "with open('/Users/jzeiders/Documents/Code/Learnings/GraduateML/src/Project4/submission/movies.dat', 'r', encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        movie_id, title, genres = line.strip().split('::')\n",
    "        movie_data[f\"m{movie_id}\"] = {\n",
    "            'title': title,\n",
    "            'genres': genres.split('|')\n",
    "        }\n",
    "\n",
    "print(f\"Loaded ratings matrix with shape: {ratings_matrix.shape}\")\n",
    "print(f\"Loaded {len(movie_data)} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System I: Top 10 Popular Movies\n",
      "--------------------------------------------------------------------------------\n",
      "m2858: American Beauty (1999) (Score: 2.450)\n",
      "m260: Star Wars: Episode IV - A New Hope (1977) (Score: 2.205)\n",
      "m1196: Star Wars: Episode V - The Empire Strikes Back (1980) (Score: 2.125)\n",
      "m1210: Star Wars: Episode VI - Return of the Jedi (1983) (Score: 1.920)\n",
      "m2028: Saving Private Ryan (1998) (Score: 1.905)\n",
      "m1198: Raiders of the Lost Ark (1981) (Score: 1.864)\n",
      "m593: Silence of the Lambs, The (1991) (Score: 1.857)\n",
      "m2571: Matrix, The (1999) (Score: 1.851)\n",
      "m2762: Sixth Sense, The (1999) (Score: 1.794)\n",
      "m589: Terminator 2: Judgment Day (1991) (Score: 1.780)\n"
     ]
    }
   ],
   "source": [
    "def compute_popularity(ratings_matrix: pd.DataFrame) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute movie popularity based on number of ratings and average rating.\n",
    "    \n",
    "    Criteria:\n",
    "    1. Must have at least 10 ratings\n",
    "    2. Must have average rating > 3.5\n",
    "    3. Score = (average_rating * number_of_ratings) / total_possible_ratings\n",
    "    \"\"\"\n",
    "    popularity_scores = []\n",
    "    \n",
    "    for movie_id in ratings_matrix.columns:\n",
    "        ratings = ratings_matrix[movie_id]\n",
    "        num_ratings = ratings.notna().sum()\n",
    "        avg_rating = ratings.mean()\n",
    "        \n",
    "        if num_ratings >= 10 and avg_rating > 3.5:\n",
    "            popularity_score = (avg_rating * num_ratings) / ratings_matrix.shape[0]\n",
    "            popularity_scores.append((movie_id, popularity_score))\n",
    "    \n",
    "    popularity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return popularity_scores\n",
    "popular_movies = compute_popularity(ratings_matrix)[:10]\n",
    "print(\"\\nSystem I: Top 10 Popular Movies\")\n",
    "print(\"-\" * 80)\n",
    "for movie_id, score in popular_movies:\n",
    "    title = movie_data[movie_id]['title']\n",
    "    print(f\"{movie_id}: {title} (Score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: System II - Item-Based Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_chunk(args):\n",
    "    \"\"\"Compute cosine similarity for a chunk of movie pairs.\"\"\"\n",
    "    chunk, R, rated_mask = args\n",
    "    results = []\n",
    "    processed_count = 0\n",
    "    for i, j in chunk:\n",
    "        processed_count += 1\n",
    "        # Find users who rated both movies\n",
    "        common = rated_mask[:, i] & rated_mask[:, j]\n",
    "        n_common = np.sum(common)\n",
    "        \n",
    "        if n_common >= 3:\n",
    "            # Extract ratings from common users\n",
    "            Ri = R[common, i]\n",
    "            Rj = R[common, j]\n",
    "            \n",
    "            numerator = np.sum(Ri * Rj)\n",
    "            denom = np.sqrt(np.sum(Ri**2)) * np.sqrt(np.sum(Rj**2))\n",
    "            \n",
    "            if denom != 0:\n",
    "                cos_sim = numerator / denom\n",
    "                # Transform similarity to be in [0, 1]\n",
    "                sim = 0.5 + 0.5 * cos_sim\n",
    "                results.append((i, j, sim))\n",
    "    print(f\"Processed {processed_count} pairs for chunk {chunk[0][0]}\")\n",
    "    return results\n",
    "\n",
    "def compute_transformed_cosine_similarity(Rdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute transformed cosine similarities between movies in parallel.\"\"\"\n",
    "    logger.info(\"Computing similarity matrix...\")\n",
    "    R = np.asarray(Rdf)\n",
    "    num_users, num_movies = R.shape\n",
    "    \n",
    "    rated_mask = ~np.isnan(R)\n",
    "    similarities = pd.DataFrame(\n",
    "        np.full((num_movies, num_movies), np.nan, dtype=np.float64), \n",
    "        index=Rdf.columns, \n",
    "        columns=Rdf.columns\n",
    "    )\n",
    "    \n",
    "    all_pairs = list(combinations(range(num_movies), 2))\n",
    "    n_cores = cpu_count()\n",
    "    chunk_size = len(all_pairs) // (n_cores * 4)\n",
    "    chunks = [all_pairs[i:i + chunk_size] for i in range(0, len(all_pairs), chunk_size)]\n",
    "    \n",
    "    with Pool(processes=n_cores) as pool:\n",
    "        results = pool.map(compute_similarity_chunk, [(chunk, R, rated_mask) for chunk in chunks])\n",
    "    \n",
    "    for chunk_results in results:\n",
    "        for i, j, sim in chunk_results:\n",
    "            similarities.iloc[i, j] = sim\n",
    "            similarities.iloc[j, i] = sim\n",
    "    \n",
    "    # Keep only top 30 similarities per movie\n",
    "    for movie in similarities.columns:\n",
    "        movie_similarities = similarities[movie].copy()\n",
    "        movie_similarities[movie] = np.nan\n",
    "        sorted_indices = movie_similarities.sort_values(ascending=False).index[:30]\n",
    "        similarities.loc[~similarities.index.isin(sorted_indices), movie] = np.nan\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "# Center the ratings matrix\n",
    "user_means = ratings_matrix.mean(axis=1)\n",
    "centered_matrix = ratings_matrix.sub(user_means, axis=0)\n",
    "\n",
    "SIMILARITY_MATRIX_FILE = '/Users/jzeiders/Documents/Code/Learnings/GraduateML/src/Project4/submission/similarity_matrix.csv'        \n",
    "def get_similarity_matrix():\n",
    "    if os.path.exists(SIMILARITY_MATRIX_FILE):\n",
    "        # Caching because this takes a while\n",
    "        return pd.read_csv(SIMILARITY_MATRIX_FILE, index_col=0)\n",
    "    else:\n",
    "        similarity_matrix = compute_transformed_cosine_similarity(centered_matrix)\n",
    "        similarity_matrix.to_csv(SIMILARITY_MATRIX_FILE)\n",
    "        return similarity_matrix\n",
    "\n",
    "similarity_matrix = get_similarity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pairwise Similarities for Specified Movies:\n",
      "             m1       m10      m100  m1510      m260  m3212\n",
      "m1          NaN  0.512105  0.392000    NaN  0.741148    NaN\n",
      "m10    0.512105       NaN  0.547458    NaN  0.534334    NaN\n",
      "m100   0.392000  0.547458       NaN    NaN  0.329694    NaN\n",
      "m1510       NaN       NaN       NaN    NaN       NaN    NaN\n",
      "m260   0.741148  0.534334  0.329694    NaN       NaN    NaN\n",
      "m3212       NaN       NaN       NaN    NaN       NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "# Display similarities for specified movies\n",
    "movies_to_check = [\"m1\", \"m10\", \"m100\", \"m1510\", \"m260\", \"m3212\"]\n",
    "similarity_subset = similarity_matrix.loc[movies_to_check, movies_to_check]\n",
    "print(\"\\nPairwise Similarities for Specified Movies:\")\n",
    "print(similarity_subset.round(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part3(similarity_matrix: pd.DataFrame) -> pd.DataFrame:\n",
    "    out_matrix = similarity_matrix.copy()\n",
    "    for movie in out_matrix.index:\n",
    "         # Get similarities for current movie\n",
    "        movie_similarities = out_matrix.loc[movie].copy()\n",
    "        # Set self-similarity to NaN\n",
    "        movie_similarities[movie] = np.nan\n",
    "        # Sort similarities\n",
    "        sorted_indices = movie_similarities.sort_values(ascending=False).index\n",
    "        # Keep only top 30\n",
    "        keep_indices = sorted_indices[:30]\n",
    "        # Set all other similarities to NaN\n",
    "        out_matrix.loc[movie, ~out_matrix.columns.isin(keep_indices)] = np.nan\n",
    "    return out_matrix\n",
    "\n",
    "\n",
    "def myIBCF(similarity_matrix: pd.DataFrame, newuser: pd.Series) -> List[str]:\n",
    "    similarity_matrix = part3(similarity_matrix)\n",
    "    \"\"\"Generate IBCF recommendations for a new user.\"\"\"\n",
    "    user_mean = newuser[newuser.notna()].mean()\n",
    "    predictions = []\n",
    "\n",
    "    for movie_i in similarity_matrix.index:\n",
    "        if pd.isna(newuser[movie_i]):\n",
    "            similar_movies = similarity_matrix.loc[movie_i].dropna()\n",
    "            rated_similar = similar_movies[newuser[similar_movies.index].notna()]\n",
    "            \n",
    "            if len(rated_similar) > 0:\n",
    "                weights = rated_similar.values\n",
    "                ratings = newuser[rated_similar.index].values\n",
    "                # Center the ratings using user's mean\n",
    "                centered_ratings = ratings - user_mean\n",
    "                # Compute prediction with baseline adjustment\n",
    "                weighted_sum = np.sum(weights * centered_ratings)\n",
    "                weight_sum = np.sum(np.abs(weights))  # Use absolute weights for normalization\n",
    "                if weight_sum > 0:  # Avoid division by zero\n",
    "                    prediction = user_mean + (weighted_sum / weight_sum)\n",
    "                    # Clip predictions to valid rating range (1-5)\n",
    "                    prediction = np.clip(prediction, 1, 5)\n",
    "                    predictions.append((movie_i, prediction))\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if len(predictions) < 10:\n",
    "        popular_movies = compute_popularity(ratings_matrix)\n",
    "        new_predictions = [p for p in popular_movies if p[0] not in [p[0] for p in predictions] and pd.isna(newuser[p[0]])]\n",
    "        predictions.extend(new_predictions[:10 - len(predictions)])\n",
    "    \n",
    "    return [p[0] for p in predictions[:10]]\n",
    "\n",
    "## Part 3: Testing and Validation\n",
    "\n",
    "def validate_recommendations(user_id: str, recommendations: List[str], movie_data: Dict):\n",
    "    \"\"\"Validate recommendations against known correct movies.\"\"\"\n",
    "    if user_id == 'u1181':\n",
    "        required_top_3 = ['m3732', 'm749', 'm3899']\n",
    "        expected_label = \"Required top 3\"\n",
    "        top_k = 3\n",
    "    else:\n",
    "        required_top_10 = ['m1017', 'm2805', 'm3269', 'm691', 'm74', \n",
    "                          'm765', 'm1100', 'm1468', 'm1541', 'm158']\n",
    "        required_top_3 = required_top_10\n",
    "        expected_label = \"Expected top 10\"\n",
    "        top_k = 10\n",
    "        \n",
    "    top_k_found = [movie for movie in required_top_3 if movie in recommendations[:top_k]]\n",
    "    print(f\"\\nValidation Results for {user_id}:\")\n",
    "    print(f\"{expected_label}: {', '.join(required_top_3)}\")\n",
    "    print(f\"Found in top {top_k}: {', '.join(top_k_found)}\")\n",
    "    print(f\"Top {top_k} accuracy: {len(top_k_found)}/{len(required_top_3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing recommendations for user u1181:\n",
      "['m2858', 'm318', 'm1968', 'm2804', 'm3418', 'm1073', 'm364', 'm3897', 'm36', 'm1912']\n",
      "\n",
      "Testing recommendations for hypothetical user (m1613:5, m1755:4):\n",
      "['m2858', 'm260', 'm1196', 'm1210', 'm2028', 'm1198', 'm593', 'm2571', 'm2762', 'm589']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting recommendations for user u1181:\")\n",
    "user_ratings = ratings_matrix.loc['u1181']\n",
    "recommendations = myIBCF(similarity_matrix, user_ratings)\n",
    "print(recommendations)\n",
    "\n",
    "# Test case 2: Hypothetical user\n",
    "print(\"\\nTesting recommendations for hypothetical user (m1613:5, m1755:4):\")\n",
    "hypo_user = pd.Series(np.nan, index=ratings_matrix.columns)\n",
    "hypo_user['m1613'] = 5\n",
    "hypo_user['m1755'] = 4\n",
    "recommendations = myIBCF(similarity_matrix, hypo_user)\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
