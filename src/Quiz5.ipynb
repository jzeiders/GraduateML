{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1\n",
    "# AIC,FTEST\n",
    "\n",
    "# Problem 2\n",
    "# Third derivative isn't necessarily continous\n",
    "\n",
    "# Problem 3\n",
    "# It has to be the cubic spline as it's the only one that could take 6 points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 4: 2\n",
      "Problem 5: -1\n",
      "Problem 6: -3.0\n"
     ]
    }
   ],
   "source": [
    "# Problem 4,5,6,7\n",
    "def g(x):\n",
    "    return 1 + 2*x - x**3\n",
    "def g_prime(x):\n",
    "    return 2 - 3*x**2\n",
    "def g_double_prime(x):\n",
    "    return -6*x\n",
    "\n",
    "ans4 = g(1)\n",
    "ans5 = g_prime(1)\n",
    "ans6 = g_double_prime(1) / 2\n",
    "print(f\"Problem 4: {ans4}\")\n",
    "print(f\"Problem 5: {ans5}\")\n",
    "print(f\"Problem 6: {ans6}\")\n",
    "print(f\"Problem 7: NA\")\n",
    "\n",
    "\n",
    "# Take 1\n",
    "# 2,-1,-3,NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual Sum of Squares: 1.93\n",
      "Predicted nox when dis=6: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jzeiders/Documents/Code/Learnings/GraduateML/.direnv/python-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    nox   R-squared:                       0.715\n",
      "Model:                            OLS   Adj. R-squared:                  0.713\n",
      "Method:                 Least Squares   F-statistic:                     419.3\n",
      "Date:                Sat, 21 Sep 2024   Prob (F-statistic):          2.71e-136\n",
      "Time:                        16:27:31   Log-Likelihood:                 690.44\n",
      "No. Observations:                 506   AIC:                            -1373.\n",
      "Df Residuals:                     502   BIC:                            -1356.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9341      0.021     45.110      0.000       0.893       0.975\n",
      "x1            -0.1821      0.015    -12.389      0.000      -0.211      -0.153\n",
      "x2             0.0219      0.003      7.476      0.000       0.016       0.028\n",
      "x3            -0.0009      0.000     -5.124      0.000      -0.001      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                       64.176   Durbin-Watson:                   0.286\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               87.386\n",
      "Skew:                           0.917   Prob(JB):                     1.06e-19\n",
      "Kurtosis:                       3.886   Cond. No.                     2.10e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.1e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "P-value of cubic term: 0.0\n",
      "Residual Sum of Squares (4th degree): 1.93\n",
      "Predicted nox when dis=6 (4th degree): 0.44\n",
      "P-value of highest term (4th degree): 0.5894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/z903c2bn73s9_l02mz68j63h0000gn/T/ipykernel_7086/1500852911.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p_value_cubic_term = ols_model.pvalues[3]  # 4th term corresponds to x^3\n",
      "/Users/jzeiders/Documents/Code/Learnings/GraduateML/.direnv/python-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n",
      "  warnings.warn(\n",
      "/var/folders/fc/z903c2bn73s9_l02mz68j63h0000gn/T/ipykernel_7086/1500852911.py:78: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p_value_highest_term = ols_model4.pvalues[-1]  # last term corresponds to x^4\n"
     ]
    }
   ],
   "source": [
    "# Problem 8,9,10,11,12,13\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data from a local file or after downloading\n",
    "data = pd.read_csv('https://liangfgithub.github.io/Data/noxData.csv')  \n",
    "# Extract features and target variable\n",
    "X = data[['dis']]\n",
    "y = data['nox']\n",
    "\n",
    "# Create a cubic polynomial feature transformer\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "\n",
    "# Transform the 'dis' feature into polynomial features (degree 3)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Fit a linear regression model on the transformed features\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "# Compute the residual sum of squares\n",
    "rss = np.sum((y - y_pred) ** 2)\n",
    "print(\"Residual Sum of Squares:\", round(rss, 2))\n",
    "\n",
    "# Predict nox when dis = 6\n",
    "dis_value = np.array([[6]])\n",
    "dis_value_poly = poly.transform(dis_value)\n",
    "nox_pred = model.predict(dis_value_poly)\n",
    "print(\"Predicted nox when dis=6:\", round(nox_pred[0], 2))\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit the model using statsmodels to get p-values\n",
    "X_poly_with_const = sm.add_constant(X_poly)  # Add constant for intercept\n",
    "ols_model = sm.OLS(y, X_poly_with_const).fit()\n",
    "\n",
    "# Check p-values\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Check p-value of the cubic term\n",
    "p_value_cubic_term = ols_model.pvalues[3]  # 4th term corresponds to x^3\n",
    "print(\"P-value of cubic term:\", round(p_value_cubic_term, 4))\n",
    "\n",
    "# Create a fourth-degree polynomial feature transformer\n",
    "poly4 = PolynomialFeatures(degree=4)\n",
    "\n",
    "# Transform the 'dis' feature into polynomial features (degree 4)\n",
    "X_poly4 = poly4.fit_transform(X)\n",
    "\n",
    "# Fit a linear regression model on the transformed features\n",
    "model4 = LinearRegression()\n",
    "model4.fit(X_poly4, y)\n",
    "\n",
    "# Compute the residual sum of squares\n",
    "y_pred4 = model4.predict(X_poly4)\n",
    "rss4 = np.sum((y - y_pred4) ** 2)\n",
    "print(\"Residual Sum of Squares (4th degree):\", round(rss4, 2))\n",
    "\n",
    "# Predict nox when dis = 6 for the 4th-degree model\n",
    "dis_value_poly4 = poly4.transform(dis_value)\n",
    "nox_pred4 = model4.predict(dis_value_poly4)\n",
    "print(\"Predicted nox when dis=6 (4th degree):\", round(nox_pred4[0], 2))\n",
    "\n",
    "# Check p-value of the highest polynomial term in the 4th degree model\n",
    "X_poly4_with_const = sm.add_constant(X_poly4)\n",
    "ols_model4 = sm.OLS(y, X_poly4_with_const).fit()\n",
    "\n",
    "# Check p-values and the highest term's p-value\n",
    "p_value_highest_term = ols_model4.pvalues[-1]  # last term corresponds to x^4\n",
    "print(\"P-value of highest term (4th degree):\", round(p_value_highest_term, 4))\n",
    "\n",
    "## Take 1\n",
    "# 8 -> 1.93\n",
    "# 9 ->  0.44\n",
    "# 10 -> Yes\n",
    "# 11 -> 1.93\n",
    "# 12 -> 0.44\n",
    "# 13 -> No\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 14\n",
    "# Knots Quantile & Poly? \n",
    "# The other options is DF 4 & 5 because it truncates (Take 1)\n",
    "\n",
    "# Problem 15\n",
    "# It must be 4 & 5 again? I'm not really sure.\n",
    "\n",
    "# Problem 16\n",
    "# Lambda 0 -> Passthrough all the data points\n",
    "# Lambda Inf -> Linear Regression (Right)\n",
    "# We can tune the integer for lambda (Wrong)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Key\n",
    "# 1 -> AIC, FTEST\n",
    "# 2 -> Third derivative isn't continuous\n",
    "# 3 -> Cubic Spline\n",
    "# 4 -> 2\n",
    "# 5 -> -1\n",
    "# 6 -> -3\n",
    "7: NA\n",
    "8: 1.93\n",
    "9: 0.44\n",
    "10: Yes\n",
    "11: 1.93\n",
    "12: 0.44\n",
    "13: No\n",
    "14: Def Poly, Def Intercept 4\n",
    "15: Def Median, Intercept 5\n",
    "16: It's Lamba 0 Interpolate, Lamba 1 Linear, And the linear near boundaries\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
